---
title: "README"
format:
  gfm: default
bibliography: references.bib
link-citations: true
---

# Overview

This repository contains the R code for the master’s thesis introducing random ILR–based data-augmentation techniques for compositional data. The newly proposed methods are compared with existing techniques from @gordon2022data using twelve microbiome classification tasks from @vangay2019microbiome.

This repository organizes R scripts, datasets, and outputs for the thesis project. The main analysis scripts are in the `scripts/` folder, and their filenames indicate execution order (e.g., `scripts/00_raw_data_prep` should be run first). Files in `R/` contain helper functions for other scripts in this repository. They are named after the scripts that call them, e.g. `R/00_data_prep_functions.R` is called by `scripts/00_raw_data_prep`. Raw input data is expected under `data/data_raw` and analysis outputs are saved under `results` in the appropaite subfolder in the appropriate subfolders. For example, results from experiments using random ILR augmentation techniques are saved in `results/random_ilr`.

## Project Structure

```
.
├── bash/                  # Bash scripts calling files from scripts/, used to run code on a computational server
├── data/
│   ├── data_raw/               # Unmodified source data 
│   └── data_preproc/           # Preprocessed data
├── content/               # Source code (.qmd) of Quarto files hosted on GitHub page as interactive dashboards
│   ├── _figures/               # Folder for PNG figures rendered in Quarto scripts (not tracked by Git)
│   └── _tables/                # Folder to save LaTex code of selected tables from Quarto scripts
├── docs/        
│   └── content/                # Quarto dashboards rendered to HTML
│       └── figures/                # Folder for PNG figures rendered in Quarto scripts
├── logs/                  # Folder to save errors and messages generated by Bash scripts
├── R/                     # R code of helper functions for all other files
├── renv/                  # Folder needed to recreate environment for local analysis 
├── results/
│   ├── benchmark/              # Single files with results of benchmark models
│   ├── random_ilr/             # Single results of random ilr augmentation methods
│   ├── rodriguez/              # Single results of Rodriguez augmentation methods
│   └── results_aggregated/     # Combined results for a selected method, model and pseudo-count
├── scripts/               # R scripts with the analysis code called by Bash scripts
├── _quarto.yml            # Set-up file for GitHub page hosting dashboard from docs/
├── .gitignore
└── README.md
```

## Getting Started

### Setup

1. Clone the repository.
2. Open the project in your preffered IDE.
3. Run `renv::restore()`. This restores the package versions recorded in `renv.lock` so you can reproduce the analysis that was done locally.


### Running the Pipeline

The below graph explains the workflow needed to recreate the results obtained in the thesis with the specification whether a given step was run locally in the environmant specified by the `renv.loc` or on the computational server in the custom Docker image.

GRAPH

## Data

The twelve datasets used for the experiments conducted in this project are taken from @vangay2019microbiome. The below table summarizes the exact datasets used along with its dimensionality and outcome. All datasets used in this project are taxa data that used RefSeq as the reference sequence database. 

```{r}
#| echo: false
#| message: false
#| warning: false

#TODO: save this table in Latex format to copy-paste it into your thesis 
library(dplyr)
library(knitr)
library(readr)
library(here)
library(purrr)
library(tidyr)
library(stringr)

# Create the tibble with data dimensionality and number of samples of preprcoessed datasets
directory_preproc <- here::here("data", "data_preproc")
name_from_file <- function(f) {
  m <- stringr::str_match(basename(f), "^task(\\d+)_preproc_(x_pc_half|y)")
  paste0("task", m[, 2], ifelse(m[, 3] == "x_pc_half", "_x", "_y"))
}

# List and read all matching txt files
files <- list.files(
  directory_preproc,
  pattern = "^task[0-9]+_preproc_(x_pc_half|y)\\.csv$",
  full.names = TRUE
)

purrr::walk(files, function(f) {
  obj_name <- name_from_file(f)
  data_obj <- read_csv(f, show_col_types = FALSE)
  assign(obj_name, data_obj, envir = .GlobalEnv)
})

# Get info about number of features & samples in each dataset
res <- tibble(Task = 1:12) %>%
  mutate(
    # n = number of samples
    n = map_int(Task, \(id) {
      y <- get(sprintf("task%d_y", id), envir = .GlobalEnv)
      nrow(y)
    }),

    # Class distribution
    dist = map(Task, \(id) {
      y <- get(sprintf("task%d_y", id), envir = .GlobalEnv)

      dist <- y |>
        count(Var) |>
        mutate(Var = str_to_title(Var)) |>
        pivot_wider(names_from = Var, values_from = n)

      # original two class names
      orig <- names(dist)

      dist |>
        mutate(`Class 1/ 2` = paste(orig, collapse = " / ")) |>
        rename(`# Class 1` = all_of(orig[1]), `# Class 2` = all_of(orig[2]))
    }),

    # number of predictors
    p = map_int(Task, function(id) {
      x_name <- sprintf("task%d_x", id)
      x <- get(x_name, envir = .GlobalEnv)
      x |> select(-sample_id) |> ncol()
    })
  ) |>
  unnest_wider(dist) |>
  select(Task, n, p, `Class 1/ 2`, `# Class 1`, `# Class 2`) |>
  mutate(`Class 1/ 2` = str_replace_all(`Class 1/ 2`, "_", " "))
```

```{r}
#| echo: false
desc_to_update <- c(1, 2, 7, 8, 11)

res <- res |> 
  mutate(Source = c("[@gevers2014treatment]", "[@gevers2014treatment]", 
      "[@human2012structure]", "[@human2012structure]", "[@human2012structure]", "[@human2012structure]",
      "[@kostic2012genomic]",
      "[@qin2012metagenome]", 
      "[@qin2014alterations]",
      "[@ravel2011vaginal]", "[@ravel2011vaginal]", "[@ravel2011vaginal]"),
      `Class 1/ 2` = case_when(
        Task == 1 ~ "Crohn’s disease / Healthy (ileum)",
        Task == 2 ~ "Crohn’s disease / Healthy (rectum)",
        Task == 7 ~ "Healthy / Colorectal cancer",
        Task == 8 ~ "Diabetes / Healthy",
        Task == 11 ~ "Nugent score high / Low",
        .default = `Class 1/ 2`
      ))

kable(res, format = "pipe", align = rep("c", 7))

```

To re-run the analysis, place original datasets downloaded from [@vangay2019microbiome] in `data/raw/`.

## Reproducibility
The environment used in the local analysis can be recreated by calling `renv::restore()`. The code run on computational server was executed inside of the container that was created with the use of the custom container image. The custom container image is based on the Rocker Tidyverse 4.4.3 image that was modified by adding several R packages. The image used in the analysis can be access in: LINK

## License

This project is released under the MIT License. See the [`LICENSE`](LICENSE) file for details.

## References

